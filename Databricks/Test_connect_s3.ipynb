import pandas as pd 
from pyspark.sql import * 
from pyspark.sql.functions import * 
spark = SparkSession.builder.master("local").appName("test").getOrCreate() 
spark.sparkContext._jsc.hadoopConfiguration().set("fs.s3n.awsAccessKeyId","***********") 
spark._jsc.hadoopConfiguration().set("fs.s3n.awsSecretAccessKey","*************") 
 
first_table_s3="s3://s3bucketemp/data/"
from pyspark import * 
df=spark.read.csv(first_table_s3)
df.show()
